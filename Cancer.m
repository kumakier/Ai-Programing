% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 14-Mar-2019 14:50:09
%
% This script assumes these variables are defined:
%
%   cancerInputs - input data.
%   cancerTargets - target data.
close all
clear all
load cancer_dataset.mat
rng default
x = cancerInputs;
t = cancerTargets;

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

epochs = [4 8 16 32 64];

nodes = [2 8 32];

Train_result = zeros(length(epochs),length(nodes),2);
Test_result = zeros(length(epochs),length(nodes),2);
% Create a Pattern Recognition Network
for n_epoch = 1:length(epochs)
    for m_nodes = 1:length(nodes)
        hiddenLayerSize = m_nodes;
        net = patternnet(hiddenLayerSize, trainFcn);            
        net.trainParam.epochs = epochs(n_epoch);
        
        % Choose Input and Output Pre/Post-Processing Functions
        % For a list of all processing functions type: help nnprocess
        net.input.processFcns = {'removeconstantrows','mapminmax'};

        repeat_count = 10;

        % Setup Division of Data for Training, Validation, Testing
        % For a list of all data division functions type: help nndivision
        net.divideFcn = 'dividerand';  % Divide data randomly
        net.divideMode = 'sample';  % Divide up every sample
        
        net.divideParam.trainRatio = 50/100;
        net.divideParam.valRatio = 0/100;
        net.divideParam.testRatio = 50/100;

        % Choose a Performance Function
        % For a list of all performance functions type: help nnperformance
        net.performFcn = 'crossentropy';  % Cross-Entropy

        % Choose Plot Functions
        % For a list of all plot functions type: help nnplot
        net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
            'plotconfusion', 'plotroc'};
        
        percentErrors = zeros(repeat_count,3);
        for c =  1: repeat_count
            % Train the Network
            [net,tr] = train(net,x,t);

            % Test the Network
            y = net(x);
            e = gsubtract(t,y);
            performance = perform(net,t,y);
            tind = vec2ind(t);
            yind = vec2ind(y);
            percentErrors(c,1) = sum(tind ~= yind)/numel(tind)

            % Recalculate Training, Validation and Test Performance
            %train
            trainTargets = t .* tr.trainMask{1};
            trainTargets = trainTargets(~isnan(trainTargets))';
            trainTargets = reshape(trainTargets, [2,length(trainTargets)/2]);
            trainOutput = y.* tr.trainMask{1};
            trainOutput = trainOutput(~isnan(trainOutput))';
            trainOutput = reshape(trainOutput, [2,length(trainOutput)/2]);
            trainTargetind = vec2ind(trainTargets);
            trainOutputind = vec2ind(trainOutput);
            percentErrors(c,2) = sum(trainTargetind ~= trainOutputind)/numel(trainTargetind);
            
            %Test
            testTargets = t .* tr.testMask{1};
            testTargets = testTargets(~isnan(testTargets))';
            testTargets = reshape(testTargets, [2,length(testTargets)/2]);
            testOutput = y.* tr.testMask{1};
            testOutput = testOutput(~isnan(testOutput))';
            testOutput = reshape(testOutput, [2,length(testOutput)/2]);
            testTargetind = vec2ind(testTargets);
            testOutputind = vec2ind(testOutput);
            percentErrors(c,3) = sum(testTargetind ~= testOutputind)/numel(testTargetind);
                
            %Val
            %valTargets = t .* tr.valMask{1};
            
            %Perfermances for train and test and val
            %trainPerformance = perform(net,trainTargets,y);
            %valPerformance = perform(net,valTargets,y);
            %testPerformance = perform(net,testTargets,y);

        end
% View the Network
% view(net)

        Error_Avg = mean(percentErrors(:,3))
        Error_Std = std(percentErrors(:,3))
        Test_result(n_epoch , m_nodes , :) = [Error_Avg, Error_Std];

    end
end

%Now Plot the results

figure;
hold on;
% mesh(nodes,epochs,result(:,:,1))
% subplot(2,2,1);
% for e_count = 1:length(epoch)
%     plot(1:length(nodes),Test_result(e_count,:,1),"-o")
%     hold on;
% end
% title("nodes vs error rate");
% xlabel("number of nodes");
% ylabel("error rate");
% legend
% legend("epochs");

% subplot(2,2,2);
for m_count = 1:1:length(nodes)
    plot(1:length(epochs),Test_result(:,m_count,1),"-o")
    hold on;
end
title("epochs vs error rate");
xlabel("number of epochs");
ylabel("error rate");
legend
% 
% subplot(2,2,3);
% for e_count = 1:length(epoch)
%     plot(1:length(nodes),Test_result(e_count,:,2),"-o")
%     hold on;
% end
% title("nodes vs std");
% xlabel("number of nodes");
% ylabel("std");
% legend
% legend("epochs");
% 
% subplot(2,2,4);
% for n_count = 1:length(nodes)
%     plot(1:length(epoch),Test_result(:,n_count,2),"-o")
%     hold on;
% end
% title("epochs vs std");
% xlabel("number of epochs");
% ylabel("std");
% legend
%legend("nodes");



%Find the minium test error
min_Avg = min(min(Test_result(:,:,1)));

%%Find the minium Epoch and Node to find the optimal value

[min_Epoch, min_Node]=find(Test_result==min_Avg);
min_Node = nodes(min_Node);
min_Epoch = epochs(min_Epoch);

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
% if (false)
%     % Generate MATLAB function for neural network for application
%     % deployment in MATLAB scripts or with MATLAB Compiler and Builder
%     % tools, or simply to examine the calculations your trained neural
%     % network performs.
%     genFunction(net,'myNeuralNetworkFunction');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a matrix-only MATLAB function for neural network code
%     % generation with MATLAB Coder tools.
%     genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a Simulink diagram for simulation or deployment with.
%     % Simulink Coder tools.
%     gensim(net);
% end
